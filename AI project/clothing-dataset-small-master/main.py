# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/jayy1809/Clothes-CNN/blob/main/CNN.ipynb
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import load_img
import os

# !git clone https://github.com/alexeygrigorev/clothing-dataset-small.git

path = './clothing-dataset-small/train/t-shirt'
name = '5f0a3fa0-6a3d-4b68-b213-72766a643de7.jpg'
image = os.path.join(path, name)

load_img(image)

# OR

# fullname = path + '/' + name
# load_img(fullname)

load_img(image, target_size=(299,299))
# target_size is used to resize the image

from tensorflow.keras.applications.xception import Xception, preprocess_input, decode_predictions

model = Xception(
    weights='imagenet',
    input_shape=(299,299,3)
)

img = load_img(image, target_size=(299,299))

x = np.array(img)

X = np.array([x])

X = preprocess_input(X)

prediction = model.predict(X)

prediction.shape

prediction[0,:10]

decode_predictions(prediction)

train_gen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

train_ds = train_gen.flow_from_directory(
    "clothing-dataset-small/train",
    target_size=(150, 150),
    batch_size=32
)

image_size = (150, 150)
batch_size = 32

validation_gen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

val_ds = validation_gen.flow_from_directory(
    "clothing-dataset-small/validation",
    target_size=image_size,
    batch_size=batch_size,
)

base_model = Xception(
    weights='imagenet',
    include_top=False,
    input_shape=(150, 150, 3)
)

base_model.trainable = False

inputs = keras.Input(shape=(150, 150, 3))
base = base_model(inputs, training=False)

pooling = keras.layers.GlobalAveragePooling2D()
vector = pooling(base)

outputs = keras.layers.Dense(10)(vector)

model = keras.Model(inputs, outputs)

learning_rate = 0.01
optimizer = keras.optimizers.Adam(learning_rate)

loss = keras.losses.CategoricalCrossentropy(from_logits=True)

model.compile(
    optimizer=optimizer,
    loss=loss,
    metrics=["accuracy"]
)

model_history = model.fit(train_ds, epochs=10, validation_data=val_ds)

model.summary()

model_history.history.keys()

plt.plot(model_history.history['accuracy'], label='Training Accuracy')
plt.plot(model_history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

def make_model(learning_rate):
    base_model = Xception(
        weights='imagenet',
        input_shape=(150, 150, 3),
        include_top=False
    )

    base_model.trainable = False

    inputs = keras.Input(shape=(150, 150, 3))
    base = base_model(inputs, training=False)

    vector = keras.layers.GlobalAveragePooling2D()(base)
    outputs = keras.layers.Dense(10)(vector)

    model = keras.Model(inputs, outputs)
    optimizer = keras.optimizers.Adam(learning_rate)
    loss = keras.losses.CategoricalCrossentropy(from_logits=True)

    model.compile(
        optimizer=optimizer,
        loss=loss,
        metrics=["accuracy"],
    )

    return model

models = {}

for lr in [0.1, 0.01, 0.001, 0.0001]:
    model = make_model(lr)
    model_historys = model.fit(train_ds, epochs=10, validation_data=val_ds)
    training_accuracy = model_historys.history['accuracy']
    validation_accuracy = model_historys.history['val_accuracy']

    final_training_accuracy = training_accuracy[-1]
    final_validation_accuracy = validation_accuracy[-1]

    models[lr] = {
        'model': model,
        'final_training_accuracy': final_training_accuracy,
        'final_validation_accuracy': final_validation_accuracy
    }

plt.figure(figsize=(10, 6))

for lr, results in models.items():
    plt.plot(results['model'].history.history['accuracy'], label=f"Training Accuracy (LR = {lr})", linestyle="dashed")
    plt.plot(results['model'].history.history['val_accuracy'], label=f"Validation Accuracy (LR = {lr})")

plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.title("Training and Validation Accuracy for different learning rates")
plt.legend()
plt.show()

for lr, results in models.items():
    print(f"learning rate : {lr} , accuracy : {results['model'].history.history['accuracy'][-1]} , val_accuracy : {results['model'].history.history['val_accuracy'][-1]}")

optimal_lr = 0.001

optimal_model = models[optimal_lr]['model']
optimal_model_history = optimal_model.history.history

plt.figure(figsize=(10, 6))

plt.plot(optimal_model_history['accuracy'], label=f'Training Accuracy (LR={optimal_lr})', linestyle='dashed')
plt.plot(optimal_model_history['val_accuracy'], label=f'Validation Accuracy (LR={optimal_lr})')

plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy for Optimal Learning Rate')
plt.legend()
plt.show()

checkpoint = keras.callbacks.ModelCheckpoint(
    "xception_v1_{epoch:02d}_{val_accuracy:.3f}.",
    save_best_only=True,
    monitor="val_accuracy"
)

model2 = make_model(learning_rate=0.001)
model2.fit(
    train_ds,
    epochs=10,
    validation_data=val_ds,
    callbacks=[checkpoint]
)

def make_model(learning_rate, droprate):
    base_model = Xception(
        weights='imagenet',
        include_top=False,
        input_shape=(150, 150, 3)
    )

    base_model.trainable = False

    inputs = keras.Input(shape=(150, 150, 3))
    base = base_model(inputs, training=False)
    vector = keras.layers.GlobalAveragePooling2D()(base)

    inner = keras.layers.Dense(100, activation='relu')(vector)
    drop = keras.layers.Dropout(0.2)(inner)
    outputs = keras.layers.Dense(10)(drop)

    model = keras.Model(inputs, outputs)

    optimizer = keras.optimizers.Adam(learning_rate)
    loss = keras.losses.CategoricalCrossentropy(from_logits=True)

    model.compile(
        optimizer=optimizer,
        loss=loss,
        metrics=["accuracy"]
    )

    return model

model = make_model(0.001, 0.8)
history = model.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=[checkpoint])

train_gen = ImageDataGenerator(
    shear_range=10.0,
    zoom_range=0.1,
    horizontal_flip=True,
    preprocessing_function=preprocess_input
)

train_ds = train_gen.flow_from_directory(
    "clothing-dataset-small/train",
    target_size=(150, 150),
    batch_size=32
)

validation_gen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

val_ds = validation_gen.flow_from_directory(
    "clothing-dataset-small/validation",
    target_size=image_size,
    batch_size=batch_size,
)

def make_model_large(learning_rate, droprate):
    base_model = Xception(
        weights='imagenet',
        include_top=False,
        input_shape=(299, 299, 3)
    )

    base_model.trainable = False

    inputs = keras.Input(shape=(299, 299, 3))
    base = base_model(inputs, training=False)
    vector = keras.layers.GlobalAveragePooling2D()(base)

    inner = keras.layers.Dense(100, activation='relu')(vector)
    drop = keras.layers.Dropout(0.2)(inner)
    outputs = keras.layers.Dense(10)(drop)

    model = keras.Model(inputs, outputs)

    optimizer = keras.optimizers.Adam(learning_rate)
    loss = keras.losses.CategoricalCrossentropy(from_logits=True)

    model.compile(
        optimizer=optimizer,
        loss=loss,
        metrics=["accuracy"]
    )

    return model

earlystop = keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0.001,
    patience=10,
    verbose=0,
    mode="auto",
    baseline=None,
    restore_best_weights=False,
    start_from_epoch=0,
)

model = make_model(learning_rate=0.001, droprate=0.5)
model_history_large = model.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=[checkpoint, earlystop])

test_gen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

test_ds = test_gen.flow_from_directory(
    "clothing-dataset-small/test",
    shuffle=False,
    target_size=(150, 150),
    batch_size=32,
)

model.evaluate(test_ds)

path = 'clothing-dataset-small/test/pants/c8d21106-bbdb-4e8d-83e4-bf3d14e54c16.jpg'
img = load_img(path, target_size=(150, 150))
img

x = np.array(img)
X = np.array([x])
X = preprocess_input(X)

pred = model.predict(X)

pred[0]

pred[0].argmax()

labels = {
    0: 'dress',
    1: 'hat',
    2: 'longsleeve',
    3: 'outwear',
    4: 'pants',
    5: 'shirt',
    6: 'shoes',
    7: 'shorts',
    8: 'skirt',
    9: 't-shirt'
}

labels[pred[0].argmax()]

img = load_img("clothing-dataset-small/test/longsleeve/03a33083-e7bf-414d-bd35-c56273ae779c.jpg", target_size=(150, 150))
img

x = np.array(img)
X = np.array([x])
X = preprocess_input(X)

pred = model.predict(X)
labels[pred[0].argmax()]

dropout_rates = [0.0, 0.2, 0.5, 0.8]

models = {}

for dropout_rate in dropout_rates:
    model = make_model(dropout_rate)
    checkpoint = keras.callbacks.ModelCheckpoint(f'xception_v1_{dropout_rate}.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)
    history = model.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=[checkpoint])

    max_val_accuracy_epoch = np.argmax(history.history['val_accuracy']) + 1
    max_val_accuracy = max(history.history['val_accuracy'])

    models[dropout_rate] = {'model': model, 'max_val_accuracy': max_val_accuracy, 'max_val_accuracy_epoch': max_val_accuracy_epoch}

best_dropout_rate = max(models, key=lambda x: models[x]['max_val_accuracy'])

best_model = models[best_dropout_rate]['model']

print(f'Best Dropout Rate: {best_dropout_rate}')
best_model.summary()
